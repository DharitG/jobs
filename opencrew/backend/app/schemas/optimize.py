from pydantic import BaseModel
import uuid

class IngestResponse(BaseModel):
    """
    Response model after successfully ingesting and converting a resume.
    """
    message: str
    converted_file_path: str # In a real app, might be a file ID or cloud storage URL
    # file_id: uuid.UUID # Alternative: return an ID


# --- Models for Phase 2: Parse & Model ---

class ResumeItem(BaseModel):
    """Represents a single item within a resume section (e.g., a paragraph, a bullet point)."""
    type: str  # e.g., "paragraph", "bullet", "table_row"
    content: str
    # Optional: Add paragraph/run IDs or offsets if needed for precise editing later
    # paragraph_index: int
    # run_indices: List[int]


class ResumeSection(BaseModel):
    """Represents a detected section in the resume."""
    title: str | None # Section title (e.g., "Experience", "Skills"), None if not identified
    items: list[ResumeItem]


class ParsedResume(BaseModel):
    """The overall structured representation of the parsed resume."""
    sections: list[ResumeSection]


class ParseRequest(BaseModel):
    """Request model for the parsing endpoint."""
    docx_file_path: str # Path to the converted DOCX file from the /ingest step


# Response for /parse is simply the ParsedResume model itself


# --- Models for Phase 3: Keyword Gap Analysis ---

class KeywordAnalysisRequest(BaseModel):
    """Request model for the keyword gap analysis endpoint."""
    job_description: str
    parsed_resume: ParsedResume # The structured resume from the /parse step


class MissingTerm(BaseModel):
    """Represents a keyword/phrase found in the job description but potentially missing or underrepresented in the resume."""
    term: str
    score: float # e.g., TF-IDF score, embedding similarity difference, etc.


class KeywordAnalysisResponse(BaseModel):
    """Response model containing the list of missing terms."""
    missing_terms: list[MissingTerm]


# --- Models for Phase 4: Rewrite Engine ---

class RewriteRequest(BaseModel):
    """Request model for the rewrite endpoint."""
    original_item: ResumeItem  # The specific item (e.g., bullet point) to rewrite
    missing_terms: list[str]   # List of keywords/phrases to inject
    context: str | None = None # Optional context (e.g., section title, job title)


class RewriteResponse(BaseModel):
    """Response model containing the suggested rewritten text."""
    rewritten_content: str


# --- Models for Phase 5: Apply Patches ---

class Patch(BaseModel):
    """Represents a single change to apply."""
    original_content: str # The exact original text of the item to find
    rewritten_content: str # The new text to replace it with
    # Optional: Add paragraph/run indices here if implemented in parsing for more robust patching
    # paragraph_index: int


class ApplyPatchRequest(BaseModel):
    """Request model for applying patches to the DOCX."""
    original_docx_path: str # Path to the DOCX file generated by /ingest
    patches: list[Patch]      # List of changes to apply


class ApplyPatchResponse(BaseModel):
    """Response model after applying patches."""
    message: str
    modified_docx_path: str # Path to the newly created DOCX with patches applied


# --- Models for Phase 7: Store Diff ---

class DiffRequest(BaseModel):
    """Request model for calculating the diff between two DOCX files."""
    original_docx_path: str # Path to the original DOCX (e.g., from /ingest)
    modified_docx_path: str # Path to the modified DOCX (e.g., from /apply-patches)


class DiffResponse(BaseModel):
    """Response model containing the calculated diff."""
    message: str
    diff: dict # The diff object generated by deepdiff (can be complex)
    # In a real app, might return a diff_id instead after storing it
